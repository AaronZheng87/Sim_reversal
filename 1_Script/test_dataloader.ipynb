{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0810ca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from skimage.color import rgb2hed\n",
    "import skimage\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgba2rgb\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8baeb48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Episode</th>\n",
       "      <th>Trial_idx_epi</th>\n",
       "      <th>State</th>\n",
       "      <th>Stim</th>\n",
       "      <th>Correct_response</th>\n",
       "      <th>Trial_id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e1</td>\n",
       "      <td>1</td>\n",
       "      <td>reversed</td>\n",
       "      <td>face</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>/Users/zhengyuanrui/Sim_reversal/2_Data/IMG/tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e1</td>\n",
       "      <td>2</td>\n",
       "      <td>stable</td>\n",
       "      <td>face</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>/Users/zhengyuanrui/Sim_reversal/2_Data/IMG/tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e1</td>\n",
       "      <td>3</td>\n",
       "      <td>stable</td>\n",
       "      <td>face</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>/Users/zhengyuanrui/Sim_reversal/2_Data/IMG/tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e1</td>\n",
       "      <td>4</td>\n",
       "      <td>stable</td>\n",
       "      <td>face</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>/Users/zhengyuanrui/Sim_reversal/2_Data/IMG/tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e1</td>\n",
       "      <td>5</td>\n",
       "      <td>stable</td>\n",
       "      <td>face</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>/Users/zhengyuanrui/Sim_reversal/2_Data/IMG/tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Episode  Trial_idx_epi     State  Stim  Correct_response  Trial_id  \\\n",
       "0      e1              1  reversed  face                 1         1   \n",
       "1      e1              2    stable  face                 1         2   \n",
       "2      e1              3    stable  face                 1         3   \n",
       "3      e1              4    stable  face                 1         4   \n",
       "4      e1              5    stable  face                 1         5   \n",
       "\n",
       "                                                path  \n",
       "0  /Users/zhengyuanrui/Sim_reversal/2_Data/IMG/tr...  \n",
       "1  /Users/zhengyuanrui/Sim_reversal/2_Data/IMG/tr...  \n",
       "2  /Users/zhengyuanrui/Sim_reversal/2_Data/IMG/tr...  \n",
       "3  /Users/zhengyuanrui/Sim_reversal/2_Data/IMG/tr...  \n",
       "4  /Users/zhengyuanrui/Sim_reversal/2_Data/IMG/tr...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('generated_dataframe.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8535122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#假设我们用path trial_id去预测 Correct_response\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40f0752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path,sizes=(28,28)):\n",
    "\n",
    "    image=imread(image_path)\n",
    "    if image.shape[-1]==4:\n",
    "        I = rgba2rgb(image) #read sample RGB image\n",
    "    else:\n",
    "        I=image/255.\n",
    "    I_resized = resize(I,sizes, anti_aliasing=True)\n",
    "    return I_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e10dae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#图片列表\n",
    "images=np.stack([load_image(path) for path in data['path']])\n",
    "\n",
    "trail_id=data['Trial_id'].values\n",
    "\n",
    "Correct_response=data['Correct_response'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7c554b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24, 28, 28, 3), (24,), (24,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape,trail_id.shape,Correct_response.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18980221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 19:58:24.986105: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71dbc836",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input=tf.keras.layers.Input(shape=(28,28,3),name='image')\n",
    "image_out=tf.keras.layers.Conv2D(16,kernel_size=3)(image_input)\n",
    "image_out=tf.keras.layers.Flatten()(image_out)\n",
    "image_out=tf.keras.layers.Dense(1)(image_out)\n",
    "\n",
    "series_input=tf.keras.layers.Input(shape=(1,),name='series')\n",
    "series_out=tf.keras.layers.Dense(1)(series_input)\n",
    "\n",
    "outputs=tf.keras.layers.Concatenate(axis=-1)([image_out,series_out])\n",
    "\n",
    "tf_model=tf.keras.Model(inputs=[image_input,series_input],outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42456119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 1s 577ms/step - loss: 11.4170 - acc: 0.2917\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.4170 - acc: 0.2917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fd206d3b3d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "metrics=['acc'])\n",
    "tf_model.fit(\n",
    "    {\"image\": images, \"series\": trail_id},\n",
    "     Correct_response,\n",
    "    epochs=2,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2ac6a3",
   "metadata": {},
   "source": [
    "# torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2a77ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms,models\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    #数据加载器\n",
    "    def __init__(self, images,ids,labels):\n",
    "\n",
    "        self.images= images\n",
    "        self.ids=ids\n",
    "        self.labels = labels\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "            \n",
    "        I=self.images[idx]\n",
    "        ID=self.ids[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        I = torch.tensor(I,dtype=torch.float).permute(2, 0, 1)\n",
    "        ID = torch.tensor(ID, dtype=torch.float)\n",
    "        label = torch.tensor(label, dtype=torch.float)\n",
    "        \n",
    "        return I,ID, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c66c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomImageDataset(images,trail_id, Correct_response)\n",
    "train_dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b14b989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 3, 28, 28]) torch.Size([24]) torch.Size([24])\n"
     ]
    }
   ],
   "source": [
    "for img,ID,label in train_dataloader:\n",
    "    print(img.shape,ID.shape,label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac7131a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
